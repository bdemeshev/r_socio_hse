---
title: "Untitled"
author: "Винни-Пух"
date: "5/17/2017"
output: html_document
---

Для выбора "разумных" регрессоров из большого количества можно использовать метод LASSO.

```{r}
library(tidyverse) # манипуляции с данными и графики
library(glmnet) # LASSO (ridge regression)
library(stargazer) # красивое оформление таблиц в html/latex
library(pander) # красивое оформление таблиц
library(car) # вспомогательные функции для линейных и не только моделей
```


```{r}
help(diamonds)
glimpse(diamonds)
```

Модель с большим количеством регрессоров.

МНК:

```{r}
model_A <- lm(data = diamonds, price ~ carat * cut)
summary(model_A)
linearHypothesis(model_A, "carat + carat:cut.L = 0")
```

Книжка "An R Companion to Applied Regression"

```{r}
model_B <- lm(data = diamonds, price ~ carat * cut * clarity * x + y + z)
summary(model_B)
```

Применяем лассо!

```{r}
my_happy_y <- diamonds$price
X <- model.matrix(data = diamonds, ~ carat * cut * clarity * x + y + z)
model_lasso <- glmnet(X, my_happy_y)
```

Смотрим на результаты:
```{r}
model_lasso
coef(model_lasso, s = 107.4)
```

Прогнозы:
```{r}
new <- diamonds[3, ]
new_expanded <- model.matrix(
  data = new, ~ carat * cut * clarity * x + y + z)
new_expanded
predict(model_lasso, s = 107.4, new_expanded)
```


